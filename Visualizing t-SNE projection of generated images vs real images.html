<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>  Visualizing t-SNE projection of generated images vs real images | David Molony
</title>
  <link rel="canonical" href="/Visualizing t-SNE projection of generated images vs real images.html">


  <link rel="stylesheet" href="/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="/theme/css/pygments/emacs.min.css">
  <link rel="stylesheet" href="/theme/css/theme.css">

  
  <meta name="description" content="Can t-SNE differentiate between images generated by a GAN versus the original images?">


</head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
    <div class="col-sm-4">
      <a href="/">
        <img class="img-fluid rounded" src=/images/burma.jpg alt="David Molony">
      </a>
    </div>
  <div class="col-sm-8">
    <h1 class="title"><a href="/">David Molony</a></h1>
      <p class="text-muted">Machine Learning, Data Science, Medical Imaging</p>
      <ul class="list-inline">
          <li class="list-inline-item"><a href="https://scholar.google.com/citations?user=jOp2LIMAAAAJ&hl=en" target="_blank">Google scholar</a></li>
          <li class="list-inline-item"><a href="/pdfs/David_Molony_Resume_May_2020.pdf" target="_blank">CV</a></li>
              <li class="list-inline-item text-muted">|</li>
            <li class="list-inline-item"><a href="/pages/About.html">About</a></li>
            <li class="list-inline-item"><a href="/pages/Contact.html">Contact</a></li>
            <li class=" list-inline-item text-muted">|</li>
          <li class="list-inline-item"><a class="fa fa-linkedin" href="https://www.linkedin.com/in/david-molony-7457a219/" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-twitter" href="https://twitter.com/DavidSMolony" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-github" href="https://github.com/dmolony3" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fa fa-Google scholar" href="https://scholar.google.com/citations?user=jOp2LIMAAAAJ&hl=en" target="_blank"></a></li>
      </ul>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>  Visualizing t-SNE projection of generated images vs real images
</h1>
      <hr>
  <article class="article">
    <header>
      <ul class="list-inline">
        <li class="list-inline-item text-muted" title="2020-02-19T16:30:00-05:00">
          <i class="fa fa-clock-o"></i>
          Wed 19 February 2020
        </li>
        <li class="list-inline-item">
          <i class="fa fa-folder-open-o"></i>
          <a href="/category/tensorflow.html">Tensorflow</a>
        </li>
          <li class="list-inline-item">
            <i class="fa fa-files-o"></i>
              <a href="/tag/tensorflow.html">#Tensorflow</a>,               <a href="/tag/gan.html">#GAN</a>          </li>
      </ul>
    </header>
    <div class="content">
      <p>In this post I'm going to visualize intravascular ultrasound (IVUS) images I generated using a generative adversarial network (GAN) and see if the t-SNE algorithm can seperate the images based on the raw pixels. The hypothesis is that if the generated images are visually different from real images t-SNE will identify this and we will be able to see 2 different clusters. First, I will briefly describe what IVUS images are, the image generation process and then talk about the results. If you just want to play with the projector click <a href="http://projector.tensorflow.org/?config=https://raw.githubusercontent.com/dmolony3/GAN_embedding/master/config.json">here</a>. </p>
<h3>Intravascular Ultrasound (IVUS)</h3>
<p>IVUS images are, as the name suggests, ultrasound images. The intravascular part of the name comes from the fact that the images are acquired from within an artery, as opposed to traditional ultrasound where images are acquired outside of the body. To acquire images inside of the artery the ultrasound probe is placed on a catheter and this is then inserted into the vessel of interest. IVUS is most frequently used to get high resolution images of the coronary arteries during a cardiac catheterization. These high resolution images provide much more accurate measurements of the lumen diameter and also allow the interventional cardiologist to see what type of plaque is in the artery. This knowledge allows the interventional cardiologist to know what size stent to use and how to approach expanding the stent. Below you can see an example of an IVUS image. These are 2D cross-sections of an artery and as the catheter is pulled back through the artery a whole stack of these 2D images are acquired so that the interventional cardiologist can see the entire artery.</p>
<p align="center">
<img alt="IVUS" class="img-fluid" src="images/IVUS.jpg" width="200"/>
</p>
<h3>Training the GAN</h3>
<p>For a good description of generative adversarial networks (GANs) see <a href="https://venturebeat.com/2019/12/26/gan-generative-adversarial-network-explainer-ai-machine-learning/">here</a>, but it is essentially a neural network that learns to generate new images from a training dataset. For this work I used the <a href="https://nvlabs.github.io/SPADE/">SPADE</a> algorithm. This is a GAN where the user provides the labelmap of the image as well as the image in the training dataset. SPADE uses a normalization layer that preserves the semantic content from the labelmap in the generated image. I trained the model from scratch for 50 epochs using the default parameters. At inference the user supplies a labelmap and the trained algorithm will generate a new image. The generated images were of excellent quality and for those interested in seeing if they can differentiate between real and generated images check out the below tweet.</p>
<p><blockquote class="twitter-tweet"  data-align = 'center' align="center"><a href="https://twitter.com/DavidSMolony/status/1185237368057597954">Tweet of DavidSMolony/1185237368057597954</a></blockquote> </p>
<h3>Running t-SNE with the Tensorflow Projector</h3>
<p>The tensorflow projector is a nice tool that allows us to visualize high-dimensional data such as images or word vectors in 2D or 3D space. You can use either Principal Component Analysis (PCA) or t-distributed Stochastic Neighbouring Embedding (t-SNE) for this purpose. t-SNE works by converting similarities between data points to joint probabilities and then tries to minimize the KL divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. For an awesome breakdown of t-SNE <a href="https://www.youtube.com/watch?v=NEaUSP4YerM">this</a> is a great resource. There are <a href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html">suggestions</a> that the dimensionality should be reduced to 50 prior to running t-SNE, in my own assessment this did not seem to have a visual impact.</p>
<p>I generated 1,800 IVUS images using SPADE and along with 1,800 real IVUS images reduced their dimensions by performing nearest neighbour interpolation of the original 500x500 image to 64x64. The 64x64 image is flattened to a vector of dimension 4,096 and is then saved to file for each IVUS image. I also supply a metadata file which indicates whether an image is real of fake (generated). To take a look at these files and how I created the embeddings visit <a href="github.com/dmolony3/GAN_embedding">here</a>.</p>
<h3>Results</h3>
<p>You can run the algorithm yourself by clicking <a href="http://projector.tensorflow.org/?config=https://raw.githubusercontent.com/dmolony3/GAN_embedding/master/config.json">here</a> where you will be able to manipulate the view of 3D space. In the image below, which is taken after 1000 iterations of t-SNE, you can see that the blue (generated/fake) images and red (real) images are inseparable. This suggests that - with respect to our input dimensionality - the generated images are from the same distribution as the real images.</p>
<p align="center">
<img alt="projector1" class="img-fluid" src="images/projector.gif"/>
</p>
<h3>Relabeling</h3>
<p>The real nice thing about the tensorflow projector is that we can perform relabeling of our generated images based on the t-SNE output. By using the bounding box selection tool we can select images close to our real distribution and relabel these as real (or whatever label we want). This gives us an easy way of finding good generated images to augment a training dataset with. We can then just download the new metadata.</p>
<p align="center">
<img alt="projector2" class="img-fluid" src="images/relabel.gif" width="800/"/>
</p>
<h3>Summary</h3>
<p>Obviously there are much better ways of assessing whether images are real of fake than just the raw pixels. Passing the images through the GAN discriminator would produce a far denser and feature rich representation. However, it is interesting to look at images at the raw pixel level and to see if they cluster together. The fact that only one cluster is visible over our real and generated image dataset appears to indicate that the generated images have matched the real image distribution quite nicely.</p><script src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
    </div>
  </article>
  <hr>
  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function() {
      this.page.url = '/Visualizing t-SNE projection of generated images vs real images.html';
      this.page.identifier = 'Visualizing t-SNE projection of generated images vs real images';
    };
    (function() {
      var d = document;
      var s = d.createElement('script');
      s.src = '//dmolony3.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript class="text-muted">
    Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
  </noscript>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
  <ul class="col-sm-6 list-inline">
    <li class="list-inline-item"><a href="/archives.html">Archives</a></li>
    <li class="list-inline-item"><a href="/categories.html">Categories</a></li>
      <li class="list-inline-item"><a href="/tags.html">Tags</a></li>
  </ul>
  <p class="col-sm-6 text-sm-right text-muted">
    Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a>
    / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
  </p>
</div>    </div>
  </footer>
</body>

</html>